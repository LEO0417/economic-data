#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¿åºœè¡¥è´´æ•°æ®åˆ†æå·¥å…·
åŸºäºdata_analysis_methods.txtä¸­çš„åˆ†ç±»æ–¹æ³•åˆ†ææ”¿åºœè¡¥è´´æ•°æ®
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import re

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def load_data(filename='output/3_æ”¿åºœè¡¥è´´æ•°æ®_æ ·æœ¬.csv'):
    """åŠ è½½æ•°æ®"""
    df = pd.read_csv(filename)
    return df

def classify_subsidies(df):
    """
    æ ¹æ®data_analysis_methods.txtä¸­çš„æ–¹æ³•å¯¹è¡¥è´´è¿›è¡Œåˆ†ç±»
    """
    # å®šä¹‰å…³é”®è¯å­—å…¸
    keywords = {
        'R&D_Innovation': [
            'åˆ›æ–°', 'ç ”å‘', 'ä¸“åˆ©', 'ç§‘æŠ€', 'æŠ€æœ¯', 'çŸ¥è¯†äº§æƒ', 'ç ”ç©¶', 
            'å¼€å‘', 'ç§‘å­¦', 'å‘æ˜', 'é«˜æ–°', 'æ™ºèƒ½', 'æ•°å­—åŒ–', 'ä¿¡æ¯åŒ–'
        ],
        'Industrial_Equipment': [
            'å·¥ä¸š', 'è®¾å¤‡', 'æŠ€æ”¹', 'æ”¹é€ ', 'å‡çº§', 'è½¬å‹', 'åˆ¶é€ ', 
            'ç”Ÿäº§çº¿', 'æœºæ¢°', 'è£…å¤‡', 'äº§ä¸šåŒ–'
        ],
        'Employment': [
            'å°±ä¸š', 'æ‹›è˜', 'å®ä¹ ', 'åŸ¹è®­', 'ç¨³å²—', 'ç”¨å·¥', 'åŠ³åŠ¨', 
            'èŒä¸š', 'æ¯•ä¸šç”Ÿ', 'æ‰©å²—', 'äººæ‰'
        ],
        'Environment': [
            'èŠ‚èƒ½', 'ç¯ä¿', 'æ¸…æ´', 'å‡æ’', 'æ±¡æŸ“', 'æ²»ç†', 'ç»¿è‰²', 
            'å¾ªç¯', 'ç”Ÿæ€', 'åºŸæ–™', 'æ’æ”¾'
        ],
        'General_Business': [
            'ç»è¥', 'å‡ºå£', 'å“ç‰Œ', 'ç¨æ”¶', 'å‘å±•', 'å¸‚åœº', 'è´¸æ˜“', 
            'è¥ä¸š', 'å•†åŠ¡', 'è´¢æ”¿', 'å¥–åŠ±', 'æ‰¶æŒ'
        ],
        'Other': [],
        'Unknown': ['å…¶ä»–', 'è¡¥åŠ©', 'è¡¥è´´', 'æ”¿åºœ']
    }
    
    def classify_single_subsidy(description):
        """å¯¹å•ä¸ªè¡¥è´´æè¿°è¿›è¡Œåˆ†ç±»"""
        if pd.isna(description):
            return 'Unknown'
        
        description = str(description).lower()
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„åŒ¹é…åˆ†æ•°
        scores = {}
        for category, words in keywords.items():
            if category == 'Other':
                continue
            score = sum(1 for word in words if word in description)
            scores[category] = score
        
        # æ‰¾åˆ°æœ€é«˜åˆ†æ•°çš„ç±»åˆ«
        if max(scores.values()) == 0:
            return 'Unknown'
        
        return max(scores, key=scores.get)
    
    # å¯¹æ¯ä¸ªè¡¥è´´è¿›è¡Œåˆ†ç±»
    df['subsidy_category'] = df['Fn05601'].apply(classify_single_subsidy)
    
    return df

def analyze_subsidy_distribution(df):
    """åˆ†æè¡¥è´´åˆ†å¸ƒ"""
    print("=" * 80)
    print("ğŸ“Š æ”¿åºœè¡¥è´´æ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"ğŸ“ˆ æ•°æ®æ¦‚è§ˆ:")
    print(f"   æ€»è®°å½•æ•°: {len(df):,}")
    print(f"   æ—¶é—´è·¨åº¦: {df['Year'].min():.0f} - {df['Year'].max():.0f}")
    print(f"   æ¶‰åŠä¼ä¸šæ•°: {df['Stkcd'].nunique():,}")
    print(f"   è¡¥è´´æ€»é‡‘é¢: {df['Fn05602'].sum():,.0f} å…ƒ")
    print()
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    category_stats = df.groupby('subsidy_category').agg({
        'Fn05602': ['count', 'sum', 'mean'],
        'Stkcd': 'nunique'
    }).round(2)
    
    category_stats.columns = ['è¡¥è´´æ•°é‡', 'è¡¥è´´æ€»é¢', 'å¹³å‡è¡¥è´´é¢', 'æ¶‰åŠä¼ä¸šæ•°']
    category_stats['å æ¯”(%)'] = (category_stats['è¡¥è´´æ•°é‡'] / len(df) * 100).round(2)
    
    print("ğŸ“‹ æŒ‰è¡¥è´´ç±»åˆ«ç»Ÿè®¡:")
    print(category_stats.sort_values('è¡¥è´´æ€»é¢', ascending=False))
    print()
    
    # æŒ‰å¹´ä»½ç»Ÿè®¡
    yearly_stats = df.groupby('Year').agg({
        'Fn05602': ['count', 'sum'],
        'Stkcd': 'nunique'
    }).round(2)
    yearly_stats.columns = ['è¡¥è´´æ•°é‡', 'è¡¥è´´æ€»é¢', 'æ¶‰åŠä¼ä¸šæ•°']
    
    print("ğŸ“… æŒ‰å¹´ä»½ç»Ÿè®¡ (å‰10å¹´):")
    print(yearly_stats.sort_values('è¡¥è´´æ€»é¢', ascending=False).head(10))
    print()
    
    return category_stats, yearly_stats

def analyze_keywords(df):
    """åˆ†æè¡¥è´´æè¿°ä¸­çš„å…³é”®è¯"""
    print("ğŸ” è¡¥è´´æè¿°å…³é”®è¯åˆ†æ:")
    
    # æå–æ‰€æœ‰è¡¥è´´æè¿°
    all_descriptions = ' '.join(df['Fn05601'].dropna().astype(str))
    
    # å¸¸è§å…³é”®è¯
    common_words = [
        'è¡¥è´´', 'è¡¥åŠ©', 'èµ„é‡‘', 'å¥–åŠ±', 'ä¸“é¡¹', 'é¡¹ç›®', 'æŠ€æœ¯', 'å‘å±•',
        'ä¼ä¸š', 'äº§ä¸š', 'åˆ›æ–°', 'ç ”å‘', 'ç§‘æŠ€', 'å·¥ä¸š', 'è´¢æ”¿', 'æ”¿åºœ'
    ]
    
    word_counts = {}
    for word in common_words:
        count = all_descriptions.count(word)
        word_counts[word] = count
    
    # æŒ‰å‡ºç°é¢‘æ¬¡æ’åº
    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    
    print("   å…³é”®è¯å‡ºç°é¢‘æ¬¡:")
    for word, count in sorted_words[:15]:
        print(f"   {word}: {count}")
    print()

def analyze_by_test_variables(df):
    """åˆ†ætestå’ŒTestå˜é‡"""
    print("ğŸ§ª testå’ŒTestå˜é‡åˆ†æ:")
    
    # testå˜é‡åˆ†æ
    test_stats = df.groupby('test').agg({
        'Fn05602': ['count', 'sum', 'mean'],
        'subsidy_category': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'
    }).round(2)
    
    print("   testå˜é‡ç»Ÿè®¡:")
    print(f"   test=0: {(df['test']==0).sum()} æ¡è®°å½•")
    print(f"   test=1: {(df['test']==1).sum()} æ¡è®°å½•")
    print()
    
    # Testå˜é‡åˆ†æ
    Test_stats = df.groupby('Test').agg({
        'Fn05602': ['count', 'sum', 'mean']
    }).round(2)
    
    print("   Testå˜é‡ç»Ÿè®¡:")
    print(f"   Test=0: {(df['Test']==0).sum()} æ¡è®°å½•")
    print(f"   Test=1: {(df['Test']==1).sum()} æ¡è®°å½•")
    print()

def create_visualizations(df, category_stats, yearly_stats):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. è¡¥è´´ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
    category_counts = df['subsidy_category'].value_counts()
    axes[0,0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')
    axes[0,0].set_title('è¡¥è´´ç±»åˆ«åˆ†å¸ƒ')
    
    # 2. å¹´åº¦è¡¥è´´è¶‹åŠ¿
    yearly_amount = df.groupby('Year')['Fn05602'].sum() / 1e8  # è½¬æ¢ä¸ºäº¿å…ƒ
    axes[0,1].plot(yearly_amount.index, yearly_amount.values, marker='o')
    axes[0,1].set_title('å¹´åº¦è¡¥è´´æ€»é¢è¶‹åŠ¿')
    axes[0,1].set_xlabel('å¹´ä»½')
    axes[0,1].set_ylabel('è¡¥è´´æ€»é¢(äº¿å…ƒ)')
    axes[0,1].tick_params(axis='x', rotation=45)
    
    # 3. è¡¥è´´é‡‘é¢åˆ†å¸ƒç®±çº¿å›¾
    df_plot = df[df['Fn05602'] > 0]  # æ’é™¤0å€¼
    axes[1,0].boxplot([np.log10(df_plot[df_plot['subsidy_category']==cat]['Fn05602']) 
                       for cat in category_counts.index if cat in df_plot['subsidy_category'].values])
    axes[1,0].set_xticklabels(category_counts.index, rotation=45)
    axes[1,0].set_title('å„ç±»åˆ«è¡¥è´´é‡‘é¢åˆ†å¸ƒ(log10)')
    axes[1,0].set_ylabel('è¡¥è´´é‡‘é¢(log10)')
    
    # 4. test vs Test äº¤å‰è¡¨
    cross_tab = pd.crosstab(df['test'], df['Test'])
    sns.heatmap(cross_tab, annot=True, fmt='d', ax=axes[1,1])
    axes[1,1].set_title('test vs Test äº¤å‰åˆ†å¸ƒ')
    
    plt.tight_layout()
    plt.savefig('output/5_subsidy_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½æ•°æ®
    df = load_data()
    
    # åˆ†ç±»è¡¥è´´
    df = classify_subsidies(df)
    
    # åˆ†æè¡¥è´´åˆ†å¸ƒ
    category_stats, yearly_stats = analyze_subsidy_distribution(df)
    
    # å…³é”®è¯åˆ†æ
    analyze_keywords(df)
    
    # testå˜é‡åˆ†æ
    analyze_by_test_variables(df)
    
    # åˆ›å»ºå¯è§†åŒ–
    create_visualizations(df, category_stats, yearly_stats)
    
    # ä¿å­˜åˆ†æç»“æœ
    df.to_csv('output/5_æ”¿åºœè¡¥è´´æ•°æ®_åˆ†æç»“æœ.csv', index=False)
    category_stats.to_csv('output/5_è¡¥è´´ç±»åˆ«ç»Ÿè®¡.csv')
    yearly_stats.to_csv('output/5_å¹´åº¦è¡¥è´´ç»Ÿè®¡.csv')
    
    print("âœ… åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°ä»¥ä¸‹æ–‡ä»¶:")
    print("   - output/5_æ”¿åºœè¡¥è´´æ•°æ®_åˆ†æç»“æœ.csv")
    print("   - output/5_è¡¥è´´ç±»åˆ«ç»Ÿè®¡.csv") 
    print("   - output/5_å¹´åº¦è¡¥è´´ç»Ÿè®¡.csv")
    print("   - output/5_subsidy_analysis.png")

if __name__ == "__main__":
    main() 